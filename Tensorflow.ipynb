{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=tf.Variable(3, name=\"a\")\n",
    "b=tf.Variable(4, name=\"b\")\n",
    "f=tf.multiply(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mul:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result=f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss=StandardScaler()\n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.1],\n",
       "       [ 23.8],\n",
       "       [ 29.8],\n",
       "       [ 10.8],\n",
       "       [  7.2],\n",
       "       [ 16.8],\n",
       "       [ 12.7],\n",
       "       [ 35.2],\n",
       "       [ 21.2],\n",
       "       [ 21.5],\n",
       "       [ 24.5],\n",
       "       [ 21.4],\n",
       "       [ 19.2],\n",
       "       [ 30.7],\n",
       "       [ 19.5],\n",
       "       [  8.5],\n",
       "       [ 32.5],\n",
       "       [ 28.1],\n",
       "       [ 14.9],\n",
       "       [ 36. ],\n",
       "       [ 16.6],\n",
       "       [ 24.8],\n",
       "       [ 17.2],\n",
       "       [ 14.4],\n",
       "       [ 20.9],\n",
       "       [ 17.8],\n",
       "       [ 37.9],\n",
       "       [ 46.7],\n",
       "       [ 14. ],\n",
       "       [  7.4],\n",
       "       [ 34.6],\n",
       "       [ 12.5],\n",
       "       [ 13.8],\n",
       "       [ 13.5],\n",
       "       [ 19.1],\n",
       "       [  8.4],\n",
       "       [  8.3],\n",
       "       [ 18.9],\n",
       "       [ 13.4],\n",
       "       [ 13.5],\n",
       "       [ 27.5],\n",
       "       [ 15.4],\n",
       "       [ 19.4],\n",
       "       [ 25.2],\n",
       "       [ 22.8],\n",
       "       [ 12.6],\n",
       "       [ 22.3],\n",
       "       [ 23.7],\n",
       "       [ 16.2],\n",
       "       [ 19.6],\n",
       "       [ 23. ],\n",
       "       [ 16.4],\n",
       "       [ 21.1],\n",
       "       [ 20.3],\n",
       "       [ 21.7],\n",
       "       [ 15.6],\n",
       "       [ 20.6],\n",
       "       [ 10.2],\n",
       "       [ 48.8],\n",
       "       [ 18.7],\n",
       "       [ 28.4],\n",
       "       [ 20.6],\n",
       "       [ 16.7],\n",
       "       [ 23.4],\n",
       "       [ 12.8],\n",
       "       [ 18.2],\n",
       "       [ 18.8],\n",
       "       [ 23.1],\n",
       "       [ 34.9],\n",
       "       [ 23.1],\n",
       "       [ 48.3],\n",
       "       [ 23.7],\n",
       "       [ 16.1],\n",
       "       [ 16.6],\n",
       "       [  7. ],\n",
       "       [ 34.9],\n",
       "       [ 21.9],\n",
       "       [ 33.1],\n",
       "       [ 23.9],\n",
       "       [ 13.9],\n",
       "       [ 10.5],\n",
       "       [ 20.3],\n",
       "       [ 33.3],\n",
       "       [ 10.9],\n",
       "       [ 17.6],\n",
       "       [ 19.8],\n",
       "       [ 17.5],\n",
       "       [ 29.6],\n",
       "       [ 12.3],\n",
       "       [ 23.3],\n",
       "       [ 17.8],\n",
       "       [ 34.7],\n",
       "       [ 24.6],\n",
       "       [ 18.5],\n",
       "       [ 18.3],\n",
       "       [ 45.4],\n",
       "       [ 14.3],\n",
       "       [ 22.5],\n",
       "       [ 18.5],\n",
       "       [ 44.8],\n",
       "       [ 22.9],\n",
       "       [ 50. ],\n",
       "       [ 25. ],\n",
       "       [ 22.6],\n",
       "       [ 26.4],\n",
       "       [ 28.7],\n",
       "       [ 16.8],\n",
       "       [ 33.4],\n",
       "       [ 18.9],\n",
       "       [ 29.8],\n",
       "       [ 19.9],\n",
       "       [ 17.4],\n",
       "       [ 13.9],\n",
       "       [ 14.5],\n",
       "       [ 18.9],\n",
       "       [ 30.5],\n",
       "       [ 31.2],\n",
       "       [ 33.2],\n",
       "       [ 15.6],\n",
       "       [ 16.5],\n",
       "       [ 23.1],\n",
       "       [ 37.2],\n",
       "       [ 28.2],\n",
       "       [ 42.8],\n",
       "       [ 21.1],\n",
       "       [ 30.8],\n",
       "       [ 23.1]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape(-1,1)\n",
    "y_test.reshape(-1,1) #Need to reshape if your loss function isn't getting better.  Check y and|or scale it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, X_train.shape[1]), name='X')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None), name='y')\n",
    "\n",
    "h1 = tf.layers.dense(X, 13, name='hidden1', activation=tf.nn.relu)\n",
    "# h1=tf.layers.dense(X, 13, name=\"hidden1\", activation=tf.nn.relu)#second place is how many neurons. \n",
    "y_hat = tf.layers.dense(h1, 1, activation=None)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y, y_hat)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(.01)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "# X=tf.placeholder(dtype=tf.float32, shape=(None, X_train.shape[1]), name=\"X\")#Requires 3 parameters.  \n",
    "# y=tf.placeholder(dtype=tf.float32, shape=(None), name=\"y\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Creating layers\n",
    " \n",
    "# y_hat=tf.layers.dense(h1, 1, activation=None )#1st is what is being fed in.\n",
    "\n",
    "# loss=tf.losses.mean_squared_error(y, y_hat)#actuals and predicted\n",
    "\n",
    "# optimizer=tf.train.AdadeltaOptimizer(.01)\n",
    "\n",
    "# training_op=optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init=tf.global_variables_initializer()\n",
    "\n",
    "# with tf.Session() as sees:\n",
    "#     init.run()\n",
    "    \n",
    "#     for epoch in range(10):\n",
    "#         sess.run(training_op, feed_dict=({X:X_train, y:y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 training loss 631.295\n",
      "epoch 1 test loss 614.593\n",
      "epoch 2 training loss 622.819\n",
      "epoch 2 test loss 606.295\n",
      "epoch 3 training loss 614.569\n",
      "epoch 3 test loss 598.205\n",
      "epoch 4 training loss 606.509\n",
      "epoch 4 test loss 590.242\n",
      "epoch 5 training loss 598.654\n",
      "epoch 5 test loss 582.365\n",
      "epoch 6 training loss 590.927\n",
      "epoch 6 test loss 574.526\n",
      "epoch 7 training loss 583.316\n",
      "epoch 7 test loss 566.774\n",
      "epoch 8 training loss 575.833\n",
      "epoch 8 test loss 559.13\n",
      "epoch 9 training loss 568.436\n",
      "epoch 9 test loss 551.627\n",
      "epoch 10 training loss 561.083\n",
      "epoch 10 test loss 544.205\n",
      "epoch 11 training loss 553.761\n",
      "epoch 11 test loss 536.827\n",
      "epoch 12 training loss 546.448\n",
      "epoch 12 test loss 529.504\n",
      "epoch 13 training loss 539.117\n",
      "epoch 13 test loss 522.188\n",
      "epoch 14 training loss 531.748\n",
      "epoch 14 test loss 514.816\n",
      "epoch 15 training loss 524.377\n",
      "epoch 15 test loss 507.414\n",
      "epoch 16 training loss 516.983\n",
      "epoch 16 test loss 500.012\n",
      "epoch 17 training loss 509.558\n",
      "epoch 17 test loss 492.601\n",
      "epoch 18 training loss 502.102\n",
      "epoch 18 test loss 485.159\n",
      "epoch 19 training loss 494.608\n",
      "epoch 19 test loss 477.669\n",
      "epoch 20 training loss 487.05\n",
      "epoch 20 test loss 470.152\n",
      "epoch 21 training loss 479.433\n",
      "epoch 21 test loss 462.595\n",
      "epoch 22 training loss 471.753\n",
      "epoch 22 test loss 454.969\n",
      "epoch 23 training loss 463.996\n",
      "epoch 23 test loss 447.284\n",
      "epoch 24 training loss 456.158\n",
      "epoch 24 test loss 439.554\n",
      "epoch 25 training loss 448.232\n",
      "epoch 25 test loss 431.725\n",
      "epoch 26 training loss 440.212\n",
      "epoch 26 test loss 423.802\n",
      "epoch 27 training loss 432.1\n",
      "epoch 27 test loss 415.819\n",
      "epoch 28 training loss 423.91\n",
      "epoch 28 test loss 407.759\n",
      "epoch 29 training loss 415.636\n",
      "epoch 29 test loss 399.637\n",
      "epoch 30 training loss 407.294\n",
      "epoch 30 test loss 391.452\n",
      "epoch 31 training loss 398.891\n",
      "epoch 31 test loss 383.214\n",
      "epoch 32 training loss 390.44\n",
      "epoch 32 test loss 374.935\n",
      "epoch 33 training loss 381.96\n",
      "epoch 33 test loss 366.648\n",
      "epoch 34 training loss 373.466\n",
      "epoch 34 test loss 358.374\n",
      "epoch 35 training loss 364.975\n",
      "epoch 35 test loss 350.131\n",
      "epoch 36 training loss 356.514\n",
      "epoch 36 test loss 341.943\n",
      "epoch 37 training loss 348.099\n",
      "epoch 37 test loss 333.835\n",
      "epoch 38 training loss 339.754\n",
      "epoch 38 test loss 325.818\n",
      "epoch 39 training loss 331.499\n",
      "epoch 39 test loss 317.922\n",
      "epoch 40 training loss 323.353\n",
      "epoch 40 test loss 310.169\n",
      "epoch 41 training loss 315.335\n",
      "epoch 41 test loss 302.579\n",
      "epoch 42 training loss 307.458\n",
      "epoch 42 test loss 295.174\n",
      "epoch 43 training loss 299.74\n",
      "epoch 43 test loss 287.971\n",
      "epoch 44 training loss 292.204\n",
      "epoch 44 test loss 280.98\n",
      "epoch 45 training loss 284.858\n",
      "epoch 45 test loss 274.209\n",
      "epoch 46 training loss 277.708\n",
      "epoch 46 test loss 267.663\n",
      "epoch 47 training loss 270.758\n",
      "epoch 47 test loss 261.346\n",
      "epoch 48 training loss 264.016\n",
      "epoch 48 test loss 255.257\n",
      "epoch 49 training loss 257.485\n",
      "epoch 49 test loss 249.39\n",
      "epoch 50 training loss 251.167\n",
      "epoch 50 test loss 243.745\n",
      "epoch 51 training loss 245.054\n",
      "epoch 51 test loss 238.316\n",
      "epoch 52 training loss 239.144\n",
      "epoch 52 test loss 233.074\n",
      "epoch 53 training loss 233.43\n",
      "epoch 53 test loss 228.021\n",
      "epoch 54 training loss 227.912\n",
      "epoch 54 test loss 223.145\n",
      "epoch 55 training loss 222.571\n",
      "epoch 55 test loss 218.428\n",
      "epoch 56 training loss 217.406\n",
      "epoch 56 test loss 213.854\n",
      "epoch 57 training loss 212.402\n",
      "epoch 57 test loss 209.417\n",
      "epoch 58 training loss 207.552\n",
      "epoch 58 test loss 205.105\n",
      "epoch 59 training loss 202.85\n",
      "epoch 59 test loss 200.908\n",
      "epoch 60 training loss 198.284\n",
      "epoch 60 test loss 196.81\n",
      "epoch 61 training loss 193.846\n",
      "epoch 61 test loss 192.8\n",
      "epoch 62 training loss 189.533\n",
      "epoch 62 test loss 188.875\n",
      "epoch 63 training loss 185.351\n",
      "epoch 63 test loss 185.025\n",
      "epoch 64 training loss 181.297\n",
      "epoch 64 test loss 181.262\n",
      "epoch 65 training loss 177.364\n",
      "epoch 65 test loss 177.585\n",
      "epoch 66 training loss 173.552\n",
      "epoch 66 test loss 173.997\n",
      "epoch 67 training loss 169.87\n",
      "epoch 67 test loss 170.496\n",
      "epoch 68 training loss 166.323\n",
      "epoch 68 test loss 167.103\n",
      "epoch 69 training loss 162.907\n",
      "epoch 69 test loss 163.817\n",
      "epoch 70 training loss 159.628\n",
      "epoch 70 test loss 160.64\n",
      "epoch 71 training loss 156.482\n",
      "epoch 71 test loss 157.582\n",
      "epoch 72 training loss 153.465\n",
      "epoch 72 test loss 154.646\n",
      "epoch 73 training loss 150.59\n",
      "epoch 73 test loss 151.831\n",
      "epoch 74 training loss 147.854\n",
      "epoch 74 test loss 149.13\n",
      "epoch 75 training loss 145.25\n",
      "epoch 75 test loss 146.545\n",
      "epoch 76 training loss 142.774\n",
      "epoch 76 test loss 144.072\n",
      "epoch 77 training loss 140.428\n",
      "epoch 77 test loss 141.718\n",
      "epoch 78 training loss 138.207\n",
      "epoch 78 test loss 139.482\n",
      "epoch 79 training loss 136.107\n",
      "epoch 79 test loss 137.352\n",
      "epoch 80 training loss 134.121\n",
      "epoch 80 test loss 135.33\n",
      "epoch 81 training loss 132.239\n",
      "epoch 81 test loss 133.414\n",
      "epoch 82 training loss 130.455\n",
      "epoch 82 test loss 131.594\n",
      "epoch 83 training loss 128.763\n",
      "epoch 83 test loss 129.86\n",
      "epoch 84 training loss 127.156\n",
      "epoch 84 test loss 128.204\n",
      "epoch 85 training loss 125.633\n",
      "epoch 85 test loss 126.618\n",
      "epoch 86 training loss 124.188\n",
      "epoch 86 test loss 125.097\n",
      "epoch 87 training loss 122.806\n",
      "epoch 87 test loss 123.633\n",
      "epoch 88 training loss 121.487\n",
      "epoch 88 test loss 122.232\n",
      "epoch 89 training loss 120.223\n",
      "epoch 89 test loss 120.896\n",
      "epoch 90 training loss 119.013\n",
      "epoch 90 test loss 119.62\n",
      "epoch 91 training loss 117.854\n",
      "epoch 91 test loss 118.4\n",
      "epoch 92 training loss 116.74\n",
      "epoch 92 test loss 117.232\n",
      "epoch 93 training loss 115.675\n",
      "epoch 93 test loss 116.114\n",
      "epoch 94 training loss 114.647\n",
      "epoch 94 test loss 115.046\n",
      "epoch 95 training loss 113.659\n",
      "epoch 95 test loss 114.028\n",
      "epoch 96 training loss 112.71\n",
      "epoch 96 test loss 113.055\n",
      "epoch 97 training loss 111.801\n",
      "epoch 97 test loss 112.125\n",
      "epoch 98 training loss 110.93\n",
      "epoch 98 test loss 111.236\n",
      "epoch 99 training loss 110.096\n",
      "epoch 99 test loss 110.393\n",
      "epoch 100 training loss 109.297\n",
      "epoch 100 test loss 109.595\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
    "        train_loss=sess.run(loss, feed_dict={X:X_train, y: y_train})\n",
    "        test_loss=sess.run(loss, feed_dict={X:X_test, y: y_test})\n",
    "        print(\"epoch\", epoch+1, \"training loss\", train_loss)\n",
    "        print(\"epoch\", epoch+1, 'test loss', test_loss)\n",
    "        \n",
    "    pred=sess.run(y_hat, feed_dict={X:X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30.31616592],\n",
       "       [ 15.11377811],\n",
       "       [ 21.38415909],\n",
       "       [ 25.73465347],\n",
       "       [ 28.09474564],\n",
       "       [ 14.98321819],\n",
       "       [ 14.97454071],\n",
       "       [ 28.48284912],\n",
       "       [ 12.397089  ],\n",
       "       [ 18.90058327],\n",
       "       [ 27.84835434],\n",
       "       [ 13.50137329],\n",
       "       [ 15.10645103],\n",
       "       [ 17.31052589],\n",
       "       [ 16.60069847],\n",
       "       [ 24.88218117],\n",
       "       [ 24.01919174],\n",
       "       [ 17.2092514 ],\n",
       "       [ 21.97542953],\n",
       "       [ 21.46132469],\n",
       "       [ 16.78026962],\n",
       "       [ 25.70077324],\n",
       "       [ 21.88403702],\n",
       "       [ 13.44454861],\n",
       "       [ 28.42051697],\n",
       "       [ 23.76808167],\n",
       "       [ 25.51770782],\n",
       "       [ 21.99193382],\n",
       "       [ 22.98134232],\n",
       "       [ 27.75156593],\n",
       "       [ 29.14073372],\n",
       "       [ 22.87776947],\n",
       "       [ 20.78155327],\n",
       "       [ 12.3784914 ],\n",
       "       [ 18.12335968],\n",
       "       [ 27.67930794],\n",
       "       [ 25.22240067],\n",
       "       [ 16.27061272],\n",
       "       [ 21.80038452],\n",
       "       [ 22.31778336],\n",
       "       [ 20.71286583],\n",
       "       [ 23.67758751],\n",
       "       [ 22.64309311],\n",
       "       [ 22.42110062],\n",
       "       [ 18.55619431],\n",
       "       [ 22.75779724],\n",
       "       [ 22.17368317],\n",
       "       [  9.24096012],\n",
       "       [ 24.26679993],\n",
       "       [ 22.5968895 ],\n",
       "       [ 21.37082863],\n",
       "       [ 20.90033722],\n",
       "       [ 16.83602524],\n",
       "       [ 15.01571846],\n",
       "       [ 18.01090622],\n",
       "       [ 16.45306015],\n",
       "       [ 19.57531738],\n",
       "       [ 18.72630692],\n",
       "       [ 25.44704628],\n",
       "       [ 13.98504353],\n",
       "       [ 19.52366638],\n",
       "       [ 14.61304474],\n",
       "       [ 20.63038635],\n",
       "       [ 18.3356781 ],\n",
       "       [ 25.8673687 ],\n",
       "       [ 17.76868057],\n",
       "       [ 23.00245094],\n",
       "       [ 16.16885376],\n",
       "       [ 28.99964142],\n",
       "       [ 16.64817238],\n",
       "       [ 21.95404053],\n",
       "       [ 23.53756332],\n",
       "       [ 22.12440491],\n",
       "       [ 16.26451302],\n",
       "       [ 30.57720566],\n",
       "       [ 22.44745064],\n",
       "       [ 25.47322083],\n",
       "       [ 28.36300087],\n",
       "       [ 22.46001434],\n",
       "       [ 13.54973602],\n",
       "       [ 28.63348961],\n",
       "       [ 17.87155724],\n",
       "       [ 30.82255554],\n",
       "       [ 19.06656075],\n",
       "       [ 13.29444313],\n",
       "       [ 15.73359871],\n",
       "       [ 16.47812653],\n",
       "       [ 24.7959671 ],\n",
       "       [ 26.7858181 ],\n",
       "       [ 19.9320755 ],\n",
       "       [ 19.69506073],\n",
       "       [ 25.77132797],\n",
       "       [ 20.52776337],\n",
       "       [ 16.90632439],\n",
       "       [ 14.53928757],\n",
       "       [ 29.48374176],\n",
       "       [ 21.7551899 ],\n",
       "       [ 26.78260422],\n",
       "       [ 18.25894547],\n",
       "       [ 21.54301834],\n",
       "       [ 15.40529919],\n",
       "       [ 16.4335022 ],\n",
       "       [ 26.34290886],\n",
       "       [ 20.75862312],\n",
       "       [ 19.38515663],\n",
       "       [ 17.83613777],\n",
       "       [ 19.11011696],\n",
       "       [ 22.03437805],\n",
       "       [ 17.47516632],\n",
       "       [ 15.08977222],\n",
       "       [ 22.56799316],\n",
       "       [ 15.42481804],\n",
       "       [ 22.26279068],\n",
       "       [ 17.48925781],\n",
       "       [ 16.45768356],\n",
       "       [ 23.14813232],\n",
       "       [ 22.05185318],\n",
       "       [ 27.37234688],\n",
       "       [ 17.10538101],\n",
       "       [ 21.55739212],\n",
       "       [ 18.513134  ],\n",
       "       [ 26.26015472],\n",
       "       [ 20.45543098],\n",
       "       [ 26.65626144],\n",
       "       [ 20.56663704],\n",
       "       [ 25.32386017],\n",
       "       [ 27.62432289]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test.reshape(1,-1)\n",
    "#pred.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11654855069988246"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sklearn.metrics.r2_score(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)\n",
    "metrics.r2_score(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.1,  23.8,  29.8,  10.8,   7.2,  16.8,  12.7,  35.2,  21.2,\n",
       "         21.5,  24.5,  21.4,  19.2,  30.7,  19.5,   8.5,  32.5,  28.1,\n",
       "         14.9,  36. ,  16.6,  24.8,  17.2,  14.4,  20.9,  17.8,  37.9,\n",
       "         46.7,  14. ,   7.4,  34.6,  12.5,  13.8,  13.5,  19.1,   8.4,\n",
       "          8.3,  18.9,  13.4,  13.5,  27.5,  15.4,  19.4,  25.2,  22.8,\n",
       "         12.6,  22.3,  23.7,  16.2,  19.6,  23. ,  16.4,  21.1,  20.3,\n",
       "         21.7,  15.6,  20.6,  10.2,  48.8,  18.7,  28.4,  20.6,  16.7,\n",
       "         23.4,  12.8,  18.2,  18.8,  23.1,  34.9,  23.1,  48.3,  23.7,\n",
       "         16.1,  16.6,   7. ,  34.9,  21.9,  33.1,  23.9,  13.9,  10.5,\n",
       "         20.3,  33.3,  10.9,  17.6,  19.8,  17.5,  29.6,  12.3,  23.3,\n",
       "         17.8,  34.7,  24.6,  18.5,  18.3,  45.4,  14.3,  22.5,  18.5,\n",
       "         44.8,  22.9,  50. ,  25. ,  22.6,  26.4,  28.7,  16.8,  33.4,\n",
       "         18.9,  29.8,  19.9,  17.4,  13.9,  14.5,  18.9,  30.5,  31.2,\n",
       "         33.2,  15.6,  16.5,  23.1,  37.2,  28.2,  42.8,  21.1,  30.8,\n",
       "         23.1]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.reshape(1,-1)\n",
    "y_test.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-695d5023f875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test[:, 0], pred[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=data.target * -1 +1 \n",
    "target=target.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(data.data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss=StandardScaler()\n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X=tf.placeholder(dtype=tf.float32, shape=(None, X_train.shape[1]), name='X')\n",
    "y=tf.placeholder(dtype=tf.float32, shape=(None), name=\"y\")\n",
    "\n",
    "h1=tf.layers.dense(X,10,name=\"hidden1\", activation=tf.nn.relu)\n",
    "y_hat=tf.layers.dense(h1,1,name=\"y_hat\",activation=tf.nn.sigmoid)\n",
    "\n",
    "loss=tf.losses.log_loss(y,y_hat)\n",
    "optimizer=tf.train.AdamOptimizer()\n",
    "training_op=optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kf=KFold(4,shuffle=True, random_state=2003)\n",
    "# batches=[]\n",
    "# for train, test in kf.split(X_train,y_train):\n",
    "#     batches.append(test)\n",
    "# len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value beta2_power\n\t [[Node: beta2_power/read = Identity[T=DT_FLOAT, _class=[\"loc:@hidden1/kernel\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](beta2_power)]]\n\nCaused by op 'beta2_power/read', defined at:\n  File \"/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-149-3762d669162b>\", line 11, in <module>\n    training_op=optimizer.minimize(loss)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 298, in minimize\n    name=name)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 412, in apply_gradients\n    self._create_slots(var_list)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 116, in _create_slots\n    trainable=False)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 226, in __init__\n    expected_shape=expected_shape)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 344, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1490, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value beta2_power\n\t [[Node: beta2_power/read = Identity[T=DT_FLOAT, _class=[\"loc:@hidden1/kernel\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](beta2_power)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value beta2_power\n\t [[Node: beta2_power/read = Identity[T=DT_FLOAT, _class=[\"loc:@hidden1/kernel\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](beta2_power)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-c0e787049ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value beta2_power\n\t [[Node: beta2_power/read = Identity[T=DT_FLOAT, _class=[\"loc:@hidden1/kernel\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](beta2_power)]]\n\nCaused by op 'beta2_power/read', defined at:\n  File \"/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-149-3762d669162b>\", line 11, in <module>\n    training_op=optimizer.minimize(loss)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 298, in minimize\n    name=name)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 412, in apply_gradients\n    self._create_slots(var_list)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 116, in _create_slots\n    trainable=False)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 226, in __init__\n    expected_shape=expected_shape)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 344, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1490, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value beta2_power\n\t [[Node: beta2_power/read = Identity[T=DT_FLOAT, _class=[\"loc:@hidden1/kernel\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](beta2_power)]]\n"
     ]
    }
   ],
   "source": [
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     epochs = range(1,101)\n",
    "#     for epoch in epochs:\n",
    "#         sess.run(training_op, feed_dict={X: X_train, y: y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'StandardScaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-73ec394edcc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtraining_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtest_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    936\u001b[0m                 ' to a larger type (e.g. int64).')\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m           \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'StandardScaler'"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     init.run()\n",
    "#     epochs = list(range(1,101))\n",
    "#     training_losses = []\n",
    "#     test_losses = []\n",
    "#     for epoch in epochs:\n",
    "#         for batch in batches:\n",
    "#             X_batch = X_train[batch]\n",
    "#             y_batch = y_train[batch]\n",
    "#             sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "#         training_loss = sess.run(loss, feed_dict={X: X_train, y: y_train})\n",
    "#         training_losses.append(training_loss)\n",
    "        \n",
    "#         test_loss = sess.run(loss, feed_dict={X: X_test, y: y_test})\n",
    "#         test_losses.append(test_loss)\n",
    "        \n",
    "# plt.plot(training_losses, label='train loss')\n",
    "# plt.plot(test_losses, label='test loss')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x103512748>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEENfkhpi6EtSQwx9SWqIoS9JDfk/GIjcqLDVXGEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1061eb390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    xs = []\n",
    "    for epoch in range(100):\n",
    "        xs.append(epoch+1)\n",
    "        sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
    "        pred = sess.run(y_hat, feed_dict={X: X_test})\n",
    "        train_loss.append(sess.run(loss, feed_dict={X: X_train, y: y_train}))\n",
    "        test_loss.append(sess.run(loss, feed_dict={X: X_test, y: y_test}))\n",
    "\n",
    "plt.scatter(xs, test_loss, label='Test Loss')\n",
    "plt.scatter(xs, train_loss, label='Train_Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-daabb905486b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batches' is not defined"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "# X = tf.placeholder(dtype=tf.float32, shape=(None, X_train.shape[1]), name='X')\n",
    "# y = tf.placeholder(dtype=tf.float32, shape=(None), name='y')\n",
    "\n",
    "# h1 = tf.layers.dense(X, 30, name='hidden1', activation=tf.nn.relu)\n",
    "# h2 = tf.layers.dense(h1, 30, name='hidden2', activation=tf.nn.relu)\n",
    "# h3 = tf.layers.dense(h2, 30, name='hidden3', activation=tf.nn.relu)\n",
    "# y_hat = tf.layers.dense(h3, 1, name='y_hat', activation=tf.nn.sigmoid)\n",
    "\n",
    "# loss = tf.losses.log_loss(y, y_hat)\n",
    "\n",
    "# optimizer = tf.train.AdamOptimizer(.001)\n",
    "\n",
    "# training_op = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     init.run()\n",
    "#     epochs = list(range(1,100))\n",
    "#     training_losses = []\n",
    "#     test_losses = []\n",
    "#     for epoch in epochs:\n",
    "#         for batch in batches:\n",
    "#             X_batch = X_train[batch]\n",
    "#             y_batch = y_train[batch]\n",
    "#             sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "#         training_loss = sess.run(loss, feed_dict={X: X_train, y: y_train})\n",
    "#         training_losses.append(training_loss)\n",
    "        \n",
    "#         test_loss = sess.run(loss, feed_dict={X: X_test, y: y_test})\n",
    "#         test_losses.append(test_loss)\n",
    "        \n",
    "# plt.plot(training_losses, label='train loss')\n",
    "# plt.plot(test_losses, label='test loss')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
